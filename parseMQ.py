import os
import argparse
import random
import logging
import pandas as pd
from MQParser import MQParser

"""
This module is used to create training data for the 
HMM using the msms.txt file generated by MaxQuant
[11:36:46] ufuk:~/Projects/HMM/ck_data> head -n 1 msms.txt | tr '\t' '\n' | nl
     1	Raw file
     2	Scan number
     3	Scan index
     4	Sequence
     5	Length
     6	Missed cleavages (Trypsin/P)
     7	Missed cleavages (Chymotrypsin+)
     8	Missed cleavages (GluC;D.P)
     9	Missed cleavages (LysC/P)
    10	Modifications
    11	Modified sequence
    12	Deamidation (NQ) Probabilities
    13	Oxidation (M) Probabilities
    14	Phospho (STY) Probabilities
    15	Deamidation (NQ) Score Diffs
    16	Oxidation (M) Score Diffs
    17	Phospho (STY) Score Diffs
    18	Acetyl (Protein N-term)
    19	Deamidation (NQ)
    20	Gln->pyro-Glu
    21	Oxidation (M)
    22	Phospho (STY)
    23	Proteins
    24	Gene Names
    25	Protein Names
    26	Charge
    27	Fragmentation
    28	Mass analyzer
    29	Type
    30	Scan event number
    31	Isotope index
    32	m/z
    33	Mass
    34	Mass Error [ppm]
    35	Simple Mass Error [ppm]
    36	Retention time
    37	PEP
    38	Score
    39	Delta score
    40	Score diff
    41	Localization prob
    42	Combinatorics
    43	PIF
    44	Fraction of total spectrum
    45	Base peak fraction
    46	Precursor Full ScanNumber
    47	Precursor Intensity
    48	Precursor Apex Fraction
    49	Precursor Apex Offset
    50	Precursor Apex Offset Time
    51	Diagnostic peak Phospho (STY) Y
    52	Matches
    53	Intensities
    54	Mass Deviations [Da]
    55	Mass Deviations [ppm]
    56	Masses
    57	Number of Matches
    58	Intensity coverage
    59	Peak coverage
    60	Neutral loss level
    61	ETD identification type
    62	Reverse
    63	All scores
    64	All sequences
    65	All modified sequences
    66	id
    67	Protein group IDs
    68	Peptide ID
    69	Mod. peptide ID
    70	Evidence ID
    71	Deamidation (NQ) site IDs
    72	Oxidation (M) site IDs
    73	Phospho (STY) site IDs
"""

# Command-line interface
parser = argparse.ArgumentParser()
parser.add_argument('-i', '--input-folder', default='.', help='Directory containing the MaxQuant msms.txt file')
parser.add_argument('-f', '--file', default='msms.txt', help='Name of the file, default=msms.txt')
parser.add_argument('--sorted', default=False, action='store_true', help='toggle if the input file is pre-sorted')
parser.add_argument('-o', '--output-folder', default='.', help='where to put the resultant files')
parser.add_argument('-n', '--nslices', default=100, type=int, help='number of files to divide the shuffled keys into')
parser.add_argument('-m', '--miss_cleavage', default=1, type=int, help='maximum number of K/R allowed in the middle of the sequence')
parser.add_argument('-t', '--threshold', default=0.001, type=float, help='Threshold value for ions to be included')
parser.add_argument('-fdr', default=0.01, type=float, help='fdr cutoff')
parser.add_argument('-r', '--rseed', type=int, help='set seed for random module, useful for checking xfold')
parser.add_argument('-s', '--spectra', default='best', choices=['best', 'rand', 'med', 'ave', 'all'],
                    help='Which spectra to use in case there are multiple for a peptide')
parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-d', '--debug', default=False, action='store_true')

args = parser.parse_args()
# Set seed for random module, useful to debug and compare files
if args.rseed is not None:
    random.seed(args.rseed)


def memoryDebug(parser):
    """
    Try to find the memory leak in this file, likely source is the parser object blowing out in size
    TODO: delete when issue solved
    :param parser:
    :return:
    """
    from common_utils import get_size
    from itertools import islice
    print("{0:10}: {1:>12,}".format("Parser", get_size(parser)))
    keys = parser.getKeys()
    print(f"Number of keys: {len(keys)}")
    for key in islice(keys, 10):
        psm = parser.psms[key]
        print(f"Size of PSM: {psm.getSize()}")
        psm.listSize()


def pre_parse(f):
    import multiprocessing, subprocess, psutil

    n_proc = multiprocessing.cpu_count()
    cols = [37, 62, 23, 10, 53, 57, 68, 26, 52, 4, 38, 5, 24]
    fields = ','.join(map(str, cols))

    pdir, base = os.path.split(f)
    filename, ext = os.path.splitext(base)
    outfile = f"{filename}_preparsed.{ext}"

    cutcmd = "gcut" if psutil.OSX else "cut"
    sortcmd = "gsort" if psutil.OSX else "sort"

    shellcmd = f"{cutcmd} -f {fields} {f} | {sortcmd} -t $'\t' --parallel={n_proc} --key=7,7 -g -o {outfile}"
    print(f"Executing: '{shellcmd}'")

    subprocess.run(shellcmd, shell=True)
    preparsedfile = os.path.join(pdir, outfile)
    print("Sorting complete...")

    assert os.path.exists(preparsedfile)
    return preparsedfile


if __name__ == '__main__':

    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)

    infile = os.path.join(args.input_folder, args.file)

    if not args.sorted and (os.path.getsize(infile) >> 30) > 4:     # if the input file is too large (bigger than 4GB)
        print(f"Attempting to trim and sort the input data")
        infile = pre_parse(infile)

    with open(infile, 'r') as f:
        parser = MQParser(fdr_threshold=args.fdr, ion_threshold=args.threshold, mc=args.miss_cleavage, dodebug=False)
        reader = pd.read_csv(f, delimiter='\t', iterator=True, chunksize=100000)

        for index, chunk in enumerate(reader):
            df = pd.DataFrame(chunk)
            if not index:
                # Creates valid column names for pandas
                colnames = [col.strip().replace(" ", "_") for col in df.columns]

            df.columns = colnames
            loop = parser.processChunk(df, args.sorted)
            if args.debug:
                memoryDebug(parser)

            if not loop:  # check if FDR threshold is met
                break

    print("Finished parsing spectra")
    print(f"FDR= {parser.fdr}, pos={parser.pos}, neg={parser.neg}")

    outfolder = os.path.join(args.output_folder, "training")
    if not os.path.exists(outfolder):
        os.makedirs(outfolder)

    parser.outputResults(outfolder, args.spectra, args.nslices)
