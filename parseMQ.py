import os
import argparse
import random
import logging
import pandas as pd
from MQParser import MQParser

"""
This module is used to create training data for the 
HMM using the msms.txt file generated by MaxQuant
"""

# Command-line interface
parser = argparse.ArgumentParser()
parser.add_argument('-i', '--input-folder', default='.', help='Directory containing the MaxQuant msms.txt file')
parser.add_argument('-f', '--file', default='msms.txt', help='Name of the file, default=msms.txt')
parser.add_argument('--sorted', default=False, action='store_true', help='toggle if the input file is pre-sorted')
parser.add_argument('-o', '--output-folder', default='.', help='where to put the resultant files')
parser.add_argument('-n', '--nslices', default=100, type=int, help='number of files to divide the shuffled keys into')
parser.add_argument('-m', '--miss_cleavage', default=1, type=int, help='maximum number of K/R allowed in the middle of the sequence')
parser.add_argument('-t', '--threshold', default=0.001, type=float, help='Threshold value for ions to be included')
parser.add_argument('-fdr', default=0.01, type=float, help='fdr cutoff')
parser.add_argument('-r', '--rseed', type=int, help='set seed for random module, useful for checking xfold')
parser.add_argument('-s', '--spectra', default='top3', choices=['best', 'top1', 'top3', 'med', 'ave', 'all'],
                    help='Which spectra to use in case there are multiple for a peptide')
parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('-d', '--debug', default=False, action='store_true')

args = parser.parse_args()
# Set seed for random module, useful to debug and compare files
if args.rseed is not None:
    random.seed(args.rseed)


def memoryDebug(parser):
    """
    Try to find the memory leak in this file, likely source is the parser object blowing out in size
    TODO: delete when issue solved
    :param parser:
    :return:
    """
    from common_utils import get_size
    from itertools import islice
    print("{0:10}: {1:>12,}".format("Parser", get_size(parser)))
    keys = parser.getKeys()
    print(f"Number of keys: {len(keys)}")
    for key in islice(keys, 10):
        psm = parser.psms[key]
        print(f"Size of PSM: {psm.getSize()}")
        psm.listSize()


if __name__ == '__main__':

    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)

    infile = os.path.join(args.input_folder, args.file)
    with open(infile, 'r') as f:
        parser = MQParser()
        reader = pd.read_csv(f, delimiter='\t', iterator=True, chunksize=100000)

        for index, chunk in enumerate(reader):
            df = pd.DataFrame(chunk)
            if not index:
                # Creates valid column names for pandas
                colnames = [col.strip().replace(" ", "_") for col in df.columns]

            df.columns = colnames
            loop = parser.processChunk(df, args.sorted)
            if args.debug:
                memoryDebug(parser)

            if not loop:  # check if FDR threshold is met
                break

    print("Finished parsing spectra")
    print("FDR= {}, pos={}, neg={}".format(parser.fdr, parser.pos, parser.neg))

    outfolder = os.path.join(args.output_folder, "training")
    if not os.path.exists(outfolder):
        os.mkdir(outfolder)

    parser.outputResults(outfolder, args.spectra, args.nslices)
